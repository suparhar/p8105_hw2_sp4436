---
title: "p8105_hw2_sp4436"
author: "Sukhman Parhar"
date: "2025-09-29"
output: github_document
---

```{r Problem 1}
#Load Packages 
library(tidyverse)
library(dplyr)

#Import and clean pols-month
pols <- read_csv("fivethirtyeight_datasets/pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.name[month],   # turn number into month name
    president = if_else(prez_gop == 1, "gop", "dem")
  ) %>%
  select(-prez_dem, -prez_gop, -day)

#Check to see if it worked 
head(pols)
colnames(pols)
unique(pols$president)

#Clean snp
snp <- read_csv("fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(
    year = as.integer(year),
    year = if_else(year > 20, 1900 + year, 2000 + year),
    month = as.integer(month),
    month = month.name[month]
  ) %>%
  select(year, month, close)

#Check to see if it worked 
head(pols)
colnames(pols)

#Clean unemployment 
unemployment <- read_csv("fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"           #Pivot longer made months into rows
  ) %>%
  mutate(
    month = match(month, month.abb),     #convert abbrev to numbers
    month = month.name[month]            #turn into full month name
  )

#See if it worked 
head(unemployment)
tail(unemployment)
colnames(unemployment)

#Fix year column in unemployment 
unemployment <- unemployment %>%
  rename(year = Year)

#Merge datasets together
merged_data <- pols %>%
  left_join(snp, by = c("year", "month")) %>%
  left_join(unemployment, by = c("year", "month"))

#Check merged data 
dim(merged_data)
colnames(merged_data)
head(merged_data)
```

## Problem 1 Summary
The `pols` dataset contains information about the number of national politicians by party from 1947 to 2015, with variables including the counts of governors, senators, and representatives, as well as an indicator of whether the president was a Democrat or Republican. The dataset has `r nrow(pols)` rows and `r ncol(pols)` columns, covering the years `r min(pols$year)` through `r max(pols$year)`.

The `snp` dataset contains monthly closing values of the S&P stock index from 1950 to 2015. It has `r nrow(snp)` rows and `r ncol(snp)` columns, covering the years `r min(snp$year)` through `r max(snp$year)`.

The `unemployment` dataset includes monthly unemployment rates from 1948 to 2015, with `r nrow(unemployment)` rows and `r ncol(unemployment)` columns, covering the years `r min(unemployment$year)` through `r max(unemployment$year)`.

After merging, the combined dataset contains `r nrow(merged_data)` rows and `r ncol(merged_data)` columns. Each row corresponds to a unique year–month, and the variables include political party, the president’s party, S&P closing values, and unemployment rates. The merged dataset spans the years `r min(merged_data$year)` through `r max(merged_data$year)`.

```{r Problem 2}
#load packages
library(readxl)
library(janitor)

#Clean Mr trash
mr_trash <- read_excel(
  "202509 Trash Wheel Collection Data.xlsx",
  sheet = "Mr. Trash Wheel",
  skip = 1
) %>%
  clean_names() %>%
  drop_na(dumpster) %>%
  select(-starts_with("...")) %>%   # remove extra empty columns
  mutate(
    year = as.integer(year),
    sports_balls = as.integer(round(sports_balls, 0)), 
    wheel = "Mr. Trash Wheel"
  )

# Clean Professor Trash Wheel
prof_trash <- read_excel(
  "202509 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",
  skip = 1
) %>%
  clean_names() %>%
  drop_na(dumpster) %>%
  select(-starts_with("...")) %>%
  mutate(
    wheel = "Professor Trash Wheel",
    year = as.integer(year)
  )

# Clean Gwynnda Trash Wheel
gwynnda_trash <- read_excel(
  "202509 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynns Falls Trash Wheel",
  skip = 1
) %>%
  clean_names() %>%
  drop_na(dumpster) %>%
  select(-starts_with("...")) %>%
  mutate(
    wheel = "Gwynnda Trash Wheel",
    year = as.integer(year)
  )

#Combine into one dataset
trash_wheel <- bind_rows(mr_trash, prof_trash, gwynnda_trash)

#Check to see if the combine worked
dim(trash_wheel)
colnames(trash_wheel)
head(trash_wheel)

table(trash_wheel$wheel)

```

The combined Trash Wheel dataset contains `r nrow(trash_wheel)` observations and `r ncol(trash_wheel)` variables. The years range from 2014 to 2025. The key variables are `weight_tons`, `plastic_bottles`, `cigarette_butts`, and `homes_powered`, and the `wheel` variable that tells us who the trash was collected by.

```{r Total weight of trash collected by Professor Trash Wheel}
prof_total_weight <- trash_wheel %>%
  filter(wheel == "Professor Trash Wheel") %>%
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))
```

The total weight of trash collected by Professor Trash Wheel is `r round(prof_total_weight$total_weight, 1)` tons.

```{r Total cigarette butts collected by Gwynnda in June 2022}
gwynnda_butts_2022 <- trash_wheel %>%
  filter(wheel == "Gwynnda Trash Wheel", year == 2022, month == "June") %>%
  summarise(total_butts = sum(cigarette_butts, na.rm = TRUE))
```

In June 2022, Gwynnda collected a total of `r gwynnda_butts_2022$total_butts` cigarette butts.

```{r Problem 3}
#Packages needed for this problem no need to run if working through entire code
library(tidyverse)
library(janitor)
library(readr)

# Clean zip code dataset
zip_codes = read_csv("zillow_data/Zip Codes.csv") %>%
  clean_names() %>%
  rename(
    zip = zip_code,
    borough = county,
    neighborhood = neighborhood
  ) %>%
  select(zip, borough, neighborhood)

#Check the names of the boroughs
unique(zip_codes$borough)

#Rename buroughs
zip_codes = zip_codes %>%
  mutate(
    borough = recode(
      borough,
      "Kings" = "Brooklyn",
      "New York" = "Manhattan",
      "Richmond" = "Staten Island"
    )
  )

#Import and clean zillow data
zori = read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") %>%
  clean_names()

#Check the names of columns to help with mutate and pivot
colnames(zori)

zori_tidy = zori %>%
  rename(zip = region_name) %>% 
  pivot_longer(
    cols = starts_with("x"), #select all the date columns bc they start with x
    names_to = "date",
    values_to = "zori"
  ) %>%
  mutate(
    date = str_remove(date, "^x"),
    year = as.integer(str_sub(date, 1, 4)),
    month = as.integer(str_sub(date, 6, 7)),
    month = month.name[month]
  ) %>%
  select(zip, year, month, zori)

#Check to see if any zipcode is duplicated
zip_codes %>%
  count(zip) %>%
  filter(n > 1)

#Remove duplicates
zip_codes = zip_codes %>%
  distinct(zip, .keep_all = TRUE)

#Merge with Zillow tidy data
zori_merged = zori_tidy %>%
  left_join(zip_codes, by = "zip") %>%
  relocate(borough, neighborhood, .after = zip)

#Describe the datasest
n_obs = nrow(zori_merged)
n_zip = n_distinct(zori_merged$zip)
n_neigh = n_distinct(zori_merged$neighborhood)
n_obs; n_zip; n_neigh
```

The final dataset contains `r n_obs` observations, covering `r n_zip` unique ZIP codes and `r n_neigh` unique neighborhoods across New York City.

```{r Missing Zips}
#Make sure both have consistent character type
zip_codes <- zip_codes %>% mutate(zip = as.character(zip))
zori_tidy <- zori_tidy %>% mutate(zip = as.character(zip))

#Find ZIPs that are in zip_codes but missing from Zillow
missing_zips <- anti_join(zip_codes, zori_tidy %>% distinct(zip), by = "zip")

#View results
missing_zips

#Total number missing
n_missing <- nrow(missing_zips)

#Count by borough
missing_by_boro <- missing_zips %>%
  count(borough) %>%
  arrange(desc(n))

n_missing
missing_by_boro

#Visualize
library(ggplot2)
library(forcats)

missing_zips %>%
  count(borough) %>%
  ggplot(aes(x = fct_reorder(borough, n), y = n, fill = borough)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(
    title = "ZIP codes in metadata but missing from Zillow rent data",
    x = "Borough",
    y = "Number of Missing ZIP Codes"
  )

#Select one or two per borough for discussion
examples_missing <- missing_zips %>%
  group_by(borough) %>%
  slice_head(n = 2) %>%
  ungroup()

examples_missing
```
There are `r n_missing` ZIP codes in the metadata file that do not appear in Zillow’s rental dataset. The number of missing ZIPs varies by borough, with the largest concentration in Manhattan.
For example, ZIP 10464 (Southeast Bronx), 11224 (Southern Brooklyn), 10020 (Chelsea and Clinton, Manhattan), 11004 (Southeast Queens), and 10307 (South Shore, Staten Island) are included in the metadata but not in Zillow. These ZIP codes might be excluded because they have limited rental housing, are  commercial or industrial areas, or have too few rental transactions for Zillow.

```{r COVID-19 Analysis}
#Only have 2020 and 2021
covid_drop = zori_merged %>%
  filter(month == "January", year %in% c(2020, 2021)) %>%
  select(zip, borough, neighborhood, year, zori)

#Put 2020 and 2021 next to each other 
covid_drop_wide = covid_drop %>%
  pivot_wider(
    names_from = year,
    values_from = zori,
    names_prefix = "zori_"
  )

#Compute drop and sort
covid_drop_wide = covid_drop_wide %>%
  mutate(
    drop = zori_2021 - zori_2020
  ) %>%
  arrange(drop) %>%
  slice_head(n = 10)

covid_drop_wide
```

The table below shows the 10 ZIP codes with the largest decline in rental prices between January 2020 and January 2021:

```{r Table for drop}
covid_drop_wide
```